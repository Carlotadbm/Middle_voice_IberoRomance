##table with verbs from subcorpus NE (whole corpus)
intransitive_NE <- intransitive %>%
filter(Verbo %in% c("reir", "cagar", "mear"))
##join tables
intransitive <- rbind(intransitive_E, intransitive_NE)
##disregard metaphorical uses
corporal <- intransitive %>%
filter(Tipo_semantico != "Proceso_corporal_metaforico")
#Plot RM probability by verb
##clean table
corporal_verbs <- corporal %>%
count(Verbo, Pron_reflexivo) %>%
group_by(Verbo) %>%
mutate(total=sum(n), prop=(n/total*100))
##relevel Verbo
corporal_verbs$Verbo <- factor(corporal_verbs$Verbo, levels = c("reir", "mear", "cagar", "dormir"))
##create plot
ggplot(corporal_verbs, aes(x=Verbo,y=prop, group=Pron_reflexivo)) +
geom_col(aes(fill=Pron_reflexivo), position = "fill") +
labs(title="Frequency of the RM in intransitive verbs \ndepicting corporal processes", x="Verb", y="Frequency of the RM", fill="Reflexive Marker") +
geom_text(aes(label = n), position = position_fill(vjust = .5)) +
theme_classic() +
scale_fill_manual(values=c('darkgrey','lightgray')) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
#Typical meanings - dormir (full_table must be used)
full_table %>%
filter(Verbo == "dormir", Pron_reflexivo == "RM") %>%
group_by(Sdo_tipic_refl) %>%
count(Pron_reflexivo) %>%
ungroup() %>%
mutate(Total=sum(n), Perc = n/sum(n)*100)
#Typical meanings - cagar, mear
corporal %>%
filter(Verbo %in% c("cagar", "mear")) %>%
group_by(Verbo, Sdo_tipic_refl) %>%
count(Pron_reflexivo) %>%
mutate(Total=sum(n), Perc = n/sum(n)*100)
#datives
corporal %>%
filter(!is.na(Tipo_dativo)) %>%
mutate(Tipo_dativo = ifelse(Tipo_dativo %in% c("Afectado", "Destinatario_posesivo"), "Affected_possessor", Tipo_dativo)) %>%
group_by(Verbo, Tipo_dativo) %>%
count(Pron_reflexivo) %>%
mutate(Total=sum(n), Perc = n/sum(n)*100)
#reir map (questionnaire)
##create table
reir_q <- read_delim("reir_mapa.csv", delim = "\t") %>%
left_join(enclaves_q_todo)
#load libraries
library(tidyverse)
library(ggrepel)
library(lme4)
library(broom.mixed)
#load table
middle_voice <- read_delim("VM_fusion_blanco_revisado_3.csv", delim="\t")
#clean table
middle_voice_1 <-  middle_voice %>%
filter(Muestreo == "Exhaustivo") %>% #by subcorpus
filter(!Tipo_sintactico %in% c("Irreversible", "Transitivo_tiempo", "Indirecto", "Directo", "Sin_cambio_valencial", "Logoforico_indirecto", "Discontinuo",
"Transitivo_path", "Mediado", "Mediado_indirecto", "Logoforico", "Discontinuo_indirecto", "Transitivo", "Auxiliar")) %>% #by syntactic type
filter(!is.na(Tipo_sintactico)) %>%
mutate(Tipo_sintactico = ifelse(Tipo_sintactico == "Intransitivo", "No_valency_change", "Valency_change")) %>%
mutate(Tipo_semantico = ifelse(is.na(Tipo_semantico), "Other", Tipo_semantico)) %>%
mutate(Tipo_semantico = ifelse(Tipo_semantico %in% c("Discursivo", "Pseudopasiva", "Pseudocopulativo", "Other"), "Other", "Kemmers"))
#Mixed model
##Transform columns into factor (first level is reference level)
middle_voice_1$Pron_reflexivo <- factor(middle_voice_1$Pron_reflexivo, levels = c("No", "Si"))
middle_voice_1$Tipo_sintactico <- factor(middle_voice_1$Tipo_sintactico, levels = c("No_valency_change", "Valency_change"))
middle_voice_1$Tipo_semantico <- factor(middle_voice_1$Tipo_semantico, levels = c("Other", "Kemmers"))
middle_voice_1$COSERID <- factor(middle_voice_1$COSERID)
##calculate model
model_voice <- glmer(Pron_reflexivo ~ Tipo_sintactico + Tipo_semantico + (1|COSERID),
family = "binomial", data = middle_voice_1)
##calculate model summary statistics
summary(model_voice)
range(resid(model_voice))
hist(resid(model_voice)) #normal distribution?
##tidy model
model_voice_tidy <- tidy(model_voice, exponentiate = F, conf.int = T) #statistic es el z-value
model_voice_tidy
?tidy
model_voice_tidy %>%
mutate(across(4:9, round, 3))
model_voice_tidy %>% View()
model_voice_tidy %>%
mutate(across(4:9, round, 3))%>% View()
##tidy model
model_voice_tidy <- tidy(model_voice, exponentiate = F, conf.int = T) %>%
mutate(across(4:9, round, 3))
##write model
write_delim(model_voice_tidy, "model_voice_tidy.csv", delim = "\t")
#load library
library(tidyverse)
#load table
anticausative_ETT <- read_delim("verbosETT_tesis.csv", delim="\t")
#Calculate correlation
##clean table: remove no valid cases
anticausative_ETT <- anticausative_ETT %>%
filter(!Valencia %in% "Nada") %>% #no valid valency change
filter(!is.na(Valencia)) %>% #no valid valency change
filter(!Verbo %in% c("descansar", "pesar", "enseñar")) #they only have unmarked cases
##check number of verbs
anticausative_ETT %>%
distinct(Verbo) %>%
nrow()
##clean table: group syntactic contexts on Transitive / Intransitive
anticausative_ETT <- mutate(anticausative_ETT,
Transitividad = ifelse(Valencia %in% c("Pasiva se", "Causativo", "Reflexivo", "Absoluto"), "Transitivo",
ifelse(Valencia %in% c("Se_impersonal", "Se – impersonal", "Régimen", "Se"), "Intransitivo",
ifelse(Valencia %in% c("Ambigua", "Auxiliar"), "Nada", Valencia)))) %>%
filter(Transitividad != "Nada")
##create table with transitivity probabilites
anticausative_ETT_TrIntr <- anticausative_ETT %>%
group_by(Verbo) %>%
count(Transitividad) %>%
spread(Transitividad, n) %>%
mutate_if(is.numeric, ~(ifelse(is.na(.), 0, .))) %>%
rename(Transitive = Transitivo, Intransitive = Intransitivo) %>%
mutate(Total = Transitive + Intransitive, Prob_trans = Transitive/Total, Type = "Transitive") %>%
ungroup()
##create table transitivity (to join later)
anticausative_ETT_TrIntr2 <- anticausative_ETT_TrIntr %>%
select(Verbo, Total, Prob_trans, Type)
##create table with RM probabilities
anticausative_ETT_RM <- anticausative_ETT %>%
filter(Valencia %in% c("Intransitivo", "Se")) %>%
group_by(Verbo) %>%
count(Valencia) %>%
spread(Valencia, n) %>%
mutate_if(is.numeric, ~(ifelse(is.na(.), 0, .))) %>%
rename(RM = Se, No_RM = Intransitivo) %>%
mutate(Total = RM + No_RM, Prob_RM = RM/Total, Type = "RM") %>%
ungroup() %>%
arrange(desc(Prob_RM))
##create table RM (to join later)
anticausative_ETT_RM2 <- anticausative_ETT_RM %>%
select(Verbo, Total, Prob_RM, Type)
##join tables
anticausative_ETT_cor <- full_join(anticausative_ETT_TrIntr2, anticausative_ETT_RM2, by = "Verbo")
##plot distribution
ggplot(anticausative_ETT_cor, aes(Prob_trans, Prob_RM)) +
geom_point() +
labs(title="Correlation between frequency of the RM and transitive uses by verb", x="Probability of transitive uses", y="Probability of the RM")
##Generate data for Appendix 5
##table with RM probability
anticausative_ETT_RM3 <- anticausative_ETT_RM %>%
select(Verbo, No_RM, RM, Total, Prob_RM) %>%
rename(Total_RM = Total)
##table with transitivity probability
anticausative_ETT_TrIntr3 <- anticausative_ETT_TrIntr %>%
select(Verbo, Transitive, Intransitive, Total, Prob_trans) %>%
rename(Total_TrIntr = Total)
##join tables
anticausative_ETT_table <- full_join(anticausative_ETT_TrIntr3, anticausative_ETT_RM3, by = "Verbo")
anticausative_ETT_table
full_join(anticausative_ETT_TrIntr3, anticausative_ETT_RM3, by = "Verbo") %>%
mutate(across(c(5,9), round, 3)) %>% View()
full_join(anticausative_ETT_TrIntr3, anticausative_ETT_RM3, by = "Verbo") %>%
mutate(across(c(5,9), round, 2)) %>% View()
##join tables
anticausative_ETT_table <- full_join(anticausative_ETT_TrIntr3, anticausative_ETT_RM3, by = "Verbo") %>%
mutate(across(c(5,9), round, 2)) %>% View()
##join tables
anticausative_ETT_table <- full_join(anticausative_ETT_TrIntr3, anticausative_ETT_RM3, by = "Verbo") %>%
mutate(across(c(5,9), round, 2))
##write table
write_csv(anticausative_ETT_table, "anticausative_ETT_table.csv")
#load libraries
library(tidyverse)
library(lme4)
library(broom.mixed)
#read tables
anticausative <- read_delim("Subtabla_anticausativos2019.csv", delim=";") #COSER anticausatives
anticausative_ETT <- read_delim("verbosETT_tesis.csv", delim="\t") #ETT anticausatives
#clean and transform table from EsTenTen so as to calculate probability of transitive uses
anticausative_ETT_transitivity <- anticausative_ETT %>%
filter(!Valencia %in% "Nada") %>% #no valid valency change
filter(!is.na(Valencia)) %>% #no valid valency change
filter(!Verbo %in% c("descansar", "pesar", "enseñar")) %>%
mutate(Transitividad = ifelse(Valencia == "Pasiva se", "Transitivo",
ifelse(Valencia == "Causativo", "Transitivo",
ifelse(Valencia == "Reflexivo", "Transitivo",
ifelse(Valencia == "Absoluto", "Transitivo",
ifelse(Valencia == "Se_impersonal", "Intransitivo",
ifelse(Valencia == "Se – impersonal", "Intransitivo",
ifelse(Valencia == "Régimen", "Intransitivo",
ifelse(Valencia == "Se", "Intransitivo",
ifelse(Valencia == "Ambigua", "Nada",
ifelse(Valencia == "Auxiliar", "Nada",
Valencia))))))))))) %>%
filter(Transitividad != "Nada") %>%
group_by(Verbo) %>%
count(Transitividad) %>%
spread(Transitividad, n) %>%
mutate_if(is.numeric, ~(ifelse(is.na(.), 0, .))) %>%
rename(Transitive = Transitivo, Intransitive = Intransitivo) %>%
mutate(Prob_trans = Transitive/(Transitive + Intransitive)) %>%
ungroup() %>%
select(Verbo, Prob_trans)
#clean COSER table and join ETT table
anticausative_glm <- anticausative %>%
mutate(Area_dialectal = ifelse(Area_dialectal == "Noroeste", "Northwest", "Rest of the territory")) %>%
mutate(Animacion_sujeto = ifelse(Animacion_sujeto %in% c("Inanimado", "Evento", "Impersonal", "Vehiculo"),
"Inanimate", "Animate")) %>%
mutate(Pron_reflexivo = ifelse(Pron_reflexivo == "No", "No_RM", "RM")) %>%
mutate(Presencia_del_dativo = ifelse(Presencia_del_dativo == "No", "No_dat", "Dat")) %>%
right_join(anticausative_ETT_transitivity) %>% #join table with data from ETT, we keep only verbs for which we calculated this probability
filter(is.na(Tipo_perifrasis)) #filter out cases in periphrases
#Mixed model
##Transform into factor (first level is reference level)
anticausative_glm$Pron_reflexivo <- factor(anticausative_glm$Pron_reflexivo, levels = c("No_RM", "RM"))
anticausative_glm$Area_dialectal <- factor(anticausative_glm$Area_dialectal, levels = c("Rest of the territory", "Northwest"))
anticausative_glm$Animacion_sujeto <- factor(anticausative_glm$Animacion_sujeto, levels = c("Inanimate", "Animate"))
anticausative_glm$Presencia_del_dativo <- factor(anticausative_glm$Presencia_del_dativo, levels = c("No_dat", "Dat"))
anticausative_glm$COSERID <- factor(anticausative_glm$COSERID)
##calculate model
model_anticausative <- glmer(Pron_reflexivo ~ Area_dialectal + Animacion_sujeto + Presencia_del_dativo + Prob_trans + (1|COSERID),
family = "binomial", data = anticausative_glm)
##summary statistics of model
summary(model_anticausative)
range(resid(model_anticausative))
hist(resid(model_anticausative))#Normal distribution?
tidy(model_anticausative, exponentiate = F, conf.int = T)
##tidy model
model_anticausative_tidy <- tidy(model_anticausative, exponentiate = F, conf.int = T) %>%
mutate(across(4:9, round, 3))
##write table
write_delim(model_anticausative_tidy, "model_anticausative_tidy.csv", delim = "\t")
model_anticausative_tidy
#load library
library(tidyverse)
#load table
anticausative <- read_delim("Subtabla_anticausativos2019.csv", delim=";")
#poner a + inf (or similar)
##create table
atelic_inf <- anticausative %>%
filter(Tipo_perifrasis == "Atelica", Tiempo_verbal == "infinitivo", Clase_aspectual == "Durativo")
##check involved periphrases
atelic_inf %>%
distinct(Perifrasis) %>%
print(n = Inf)
##check cases with RM
count(atelic_inf, Pron_reflexivo)
#tener + gerundio
##create table
atelic_ger <- anticausative %>%
filter(Tipo_perifrasis == "Atelica", Tiempo_verbal == "gerundio", Clase_aspectual == "Durativo")
##check involved periphrases
atelic_ger %>%
distinct(Perifrasis)
##check cases with RM
count(atelic_ger, Pron_reflexivo)
#poner or a similar verb + a que + inflected verb in the subjunctive
##create table
atelic <- anticausative %>%
filter(Tipo_perifrasis == "Atelica", Clase_aspectual == "Durativo") %>%
mutate(Tiempo_verbal = ifelse(Tiempo_verbal %in% c("gerundio", "infinitivo"), "non-finite", "finite"))
#calculate probability of RM by type and region
atelic %>%
filter(Area_dialectal == "Resto") %>%
group_by(Tiempo_verbal) %>%
count(Pron_reflexivo) %>%
mutate(percentage = round(n/sum(n)*100, 1),
total = sum(n))
#Fisher test with the data form the rest of the territory
##generate table
atelic_resto <- atelic %>%
filter(Area_dialectal == "Resto") %>%
mutate(Tiempo_verbal = ifelse(Tiempo_verbal == "finite", "Si", "No")) #Rename variables so that positive cases: finite & RM; non-finite & No RM
##Check whether there are duplicate places (i.e. the sample is not independent)
###create logical vector (duplicated / not duplicate)
duplicate_locations <- duplicated(atelic_resto$COSERID)
###sum TRUE values
sum(duplicate_locations, na.rm = TRUE)
###histogram by COSERID
hist(count(atelic_resto,COSERID)$n)
###summary by COSERID
summary(tibble(count(atelic_resto,COSERID)$n)) #most places have between 1-3 occurrences
### Simulation of data to test the code (X and Y = variables of interest, random attribution to 180 interviews)
interview.ID <- 1:180  # numbers of the interviews (numeric indices)
interview.ID
X <- sample (0:1,1800,replace=TRUE)
Y <- c (X[1:900], sample(0:1,900,replace=TRUE))
data <- data.frame (interview = sample(interview.ID,size=1800,replace=TRUE), X, Y)
data
View(data)
View(data)
data %>%
distinct(interview.ID)
data %>%
distinct(interview)
data %>%
count(interview)
data %>%
count(interview, sort = T) %>%
head()
atelic_resto
### Bootstrapping
B = 1000
test.stat <- numeric(B)
test.stat
test.stat[1]
test.stat[1] <- fisher.test (data$X,data$Y)$estimate  # odds ratio from the sample
test.stat[1]
for (k in 2:B) {
# resample interviews
interview.boot <- sample (interview.ID,replace=TRUE)
# resample indices of individual observations from each resampled interview
ID.boot <- unlist (sapply (interview.boot, function (i) sample (which(data$interview==i),replace=TRUE) ) )
# Compute the statistic of interest from the data subsetted by the resampled indices
test.stat[k] <- fisher.test(data$X[ID.boot],data$Y[ID.boot])$estimate
}
### Summary of results
hist (test.stat)
quantile (test.stat,probs=c(0.025,0.975))
# Estimate and confidence interval calculated from original data, ignoring the clustering (too narrow)
fisher.test (data$X,data$Y)
quantile (test.stat,probs=c(0.025,0.975))
# Estimate and confidence interval calculated from original data, ignoring the clustering (too narrow)
fisher.test (data$X,data$Y)
atelic_resto
##Check whether there are duplicate places (i.e. the sample is not independent)
###create logical vector (duplicated / not duplicate)
atelic_resto %>%
count(COSERID)
##Check whether there are duplicate places (i.e. the sample is not independent)
###create logical vector (duplicated / not duplicate)
atelic_resto %>%
count(COSERID, sort = T)
###histogram by COSERID
hist(count(atelic_resto,COSERID)$n)
###summary by COSERID
summary(tibble(count(atelic_resto,COSERID)$n)) #most places have between 1-3 occurrences
atelic_resto
table(atelic_resto_random1$Pron_reflexivo, atelic_resto_random1$Tiempo_verbal)
table(atelic_resto$Pron_reflexivo, atelic_resto$Tiempo_verbal)
fisher.test(atelic_resto$Pron_reflexivo, atelic_resto$Tiempo_verbal)
fisher.test(table(atelic_resto$Pron_reflexivo, atelic_resto$Tiempo_verbal))
test.stat[1] <- fisher.test(atelic_resto$Pron_reflexivo, atelic_resto$Tiempo_verbal)$estimate  # odds ratio from the sample
atelic_resto
interview.ID
interview.boot <- sample(atelic_resto$COSERID,replace=TRUE)
interview.boot
for (k in 2:B) {
# resample interviews
interview.boot <- sample(atelic_resto$COSERID,replace=TRUE)
# resample indices of individual observations from each resampled interview
ID.boot <- unlist(sapply(interview.boot, function(i) sample(which(data$interview==i),replace=TRUE) ) )
# Compute the statistic of interest from the data subsetted by the resampled indices
test.stat[k] <- fisher.test(data$X[ID.boot],data$Y[ID.boot])$estimate
}
### Summary of results
hist (test.stat)
for (k in 2:B) {
# resample interviews
interview.boot <- sample(atelic_resto$COSERID,replace=TRUE)
# resample indices of individual observations from each resampled interview
ID.boot <- unlist(sapply(interview.boot, function(i) sample(which(data$interview==i),replace=TRUE) ) )
# Compute the statistic of interest from the data subsetted by the resampled indices
test.stat[k] <- fisher.test(atelic_resto$Pron_reflexivo[ID.boot],atelic_resto$Tiempo_verbal[ID.boot])$estimate
}
test.stat <- numeric(B)
test.stat[1] <- fisher.test(atelic_resto$Pron_reflexivo, atelic_resto$Tiempo_verbal)$estimate  # odds ratio from the sample
for (k in 2:B) {
# resample interviews
interview.boot <- sample(atelic_resto$COSERID,replace=TRUE)
# resample indices of individual observations from each resampled interview
ID.boot <- unlist(sapply(interview.boot, function(i) sample(which(data$interview==i),replace=TRUE) ) )
# Compute the statistic of interest from the data subsetted by the resampled indices
test.stat[k] <- fisher.test(atelic_resto$Pron_reflexivo[ID.boot],atelic_resto$Tiempo_verbal[ID.boot])$estimate
}
atelic_resto$Pron_reflexivo
atelic_resto$Pron_reflexivo <- as.factor(atelic_resto$Pron_reflexivo)
atelic_resto$Pron_reflexivo
atelic_resto$Tiempo_verbal <- as.factor(atelic_resto$Tiempo_verbal)
for (k in 2:B) {
# resample interviews
interview.boot <- sample(atelic_resto$COSERID,replace=TRUE)
# resample indices of individual observations from each resampled interview
ID.boot <- unlist(sapply(interview.boot, function(i) sample(which(data$interview==i),replace=TRUE) ) )
# Compute the statistic of interest from the data subsetted by the resampled indices
test.stat[k] <- fisher.test(atelic_resto$Pron_reflexivo[ID.boot],atelic_resto$Tiempo_verbal[ID.boot])$estimate
}
### Summary of results
hist (test.stat)
quantile (test.stat,probs=c(0.025,0.975))
# Estimate and confidence interval calculated from original data, ignoring the clustering (too narrow)
fisher.test (data$X,data$Y)
# Estimate and confidence interval calculated from original data, ignoring the clustering (too narrow)
fisher.test(atelic_resto$Pron_reflexivo, atelic_resto$Tiempo_verbal)
for (k in 2:B) {
# resample interviews
interview.boot <- sample(atelic_resto$COSERID,replace=TRUE)
# resample indices of individual observations from each resampled interview
ID.boot <- unlist(sapply(interview.boot, function(i) sample(which(atelic_resto$COSERID==i),replace=TRUE) ) )
# Compute the statistic of interest from the data subsetted by the resampled indices
test.stat[k] <- fisher.test(atelic_resto$Pron_reflexivo[ID.boot],atelic_resto$Tiempo_verbal[ID.boot])$estimate
}
### Summary of results
hist(test.stat)
for (k in 2:B) {
# resample interviews
interview.boot <- sample(atelic_resto$COSERID,replace=TRUE)
# resample indices of individual observations from each resampled interview
ID.boot <- unlist(sapply(interview.boot, function(i) sample(which(atelic_resto$COSERID==i),replace=TRUE) ) )
# Compute the statistic of interest from the data subsetted by the resampled indices
test.stat[k] <- fisher.test(atelic_resto$Pron_reflexivo[ID.boot],atelic_resto$Tiempo_verbal[ID.boot])$estimate
}
### Summary of results
hist(test.stat)
quantile(test.stat,probs=c(0.025,0.975))
summary(test.stat)
#load library
library(tidyverse)
#load table
anticausative <- read_delim("Subtabla_anticausativos2019.csv", delim=";")
#Generate table with datives
datives <- anticausative %>%
filter(!is.na(Tipo_dativo)) %>% #filter out cases without datives
mutate(Tipo_dativo = ifelse(Tipo_dativo %in% c("Causante_afectado", "Causante_involuntario", "Afectacion_amplia"), "Cause", #redo classification
if_else(Tipo_dativo == "Posesivo_afectado", "Possessive",
ifelse(Tipo_dativo == "Destinatario", "Goal", "Experiencer"))))
#number of examples
datives %>%
nrow()
#number of examples by area
datives %>%
count(Area_dialectal)
#Dative types per area
##create table with RM probability by dative type and area
datives_types <- datives %>%
mutate(Pron_reflexivo = ifelse(Pron_reflexivo == "No", "No RM", "RM")) %>%
mutate(Area_dialectal = ifelse(Area_dialectal == "Resto", "Rest of the territory", "Northwest")) %>%
count(Area_dialectal, Tipo_dativo, Pron_reflexivo) %>%
group_by(Area_dialectal, Tipo_dativo) %>%
mutate(total=sum(n), prop=(n/total*100))
##relevel factor
datives_types$Tipo_dativo <- factor(datives_types$Tipo_dativo, levels = c("Experiencer", "Cause", "Goal", "Possessive"))
#generate plot
ggplot(datives_types, aes(x = Tipo_dativo, y= prop, group = Pron_reflexivo)) +
geom_col(aes(fill=Pron_reflexivo), position = "fill") +
labs(title="Frequency of the RM in anticausative verbs \nby dative type and geographical area", x="Dative type", y="Frequency of the RM", fill="Reflexive Marker") +
geom_text(aes(label = n), position = position_fill(vjust = .5)) +
theme_classic() +
scale_fill_manual(values=c('darkgrey','lightgray')) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
facet_wrap(~ Area_dialectal)
#Dative types per area
##create table with RM probability by dative type and area
datives_types <- datives %>%
mutate(Pron_reflexivo = ifelse(Pron_reflexivo == "No", "No RM", "RM")) %>%
mutate(Area_dialectal = ifelse(Area_dialectal == "Resto", "Rest of the territory", "Northwest")) %>%
count(Area_dialectal, Tipo_dativo, Pron_reflexivo) %>%
group_by(Area_dialectal, Tipo_dativo) %>%
mutate(total=sum(n), prop=(n/total*100))
##relevel factor
datives_types$Tipo_dativo <- factor(datives_types$Tipo_dativo, levels = c("Experiencer", "Causer", "Goal", "Possessive"))
#generate plot
ggplot(datives_types, aes(x = Tipo_dativo, y= prop, group = Pron_reflexivo)) +
geom_col(aes(fill=Pron_reflexivo), position = "fill") +
labs(title="Frequency of the RM in anticausative verbs \nby dative type and geographical area", x="Dative type", y="Frequency of the RM", fill="Reflexive Marker") +
geom_text(aes(label = n), position = position_fill(vjust = .5)) +
theme_classic() +
scale_fill_manual(values=c('darkgrey','lightgray')) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
facet_wrap(~ Area_dialectal)
datives_types
#load table
anticausative <- read_delim("Subtabla_anticausativos2019.csv", delim=";")
#Generate table with datives
datives <- anticausative %>%
filter(!is.na(Tipo_dativo)) %>% #filter out cases without datives
mutate(Tipo_dativo = ifelse(Tipo_dativo %in% c("Causante_afectado", "Causante_involuntario", "Afectacion_amplia"), "Causer", #redo classification
if_else(Tipo_dativo == "Posesivo_afectado", "Possessive",
ifelse(Tipo_dativo == "Destinatario", "Goal", "Experiencer"))))
#number of examples
datives %>%
nrow()
#number of examples by area
datives %>%
count(Area_dialectal)
#Dative types per area
##create table with RM probability by dative type and area
datives_types <- datives %>%
mutate(Pron_reflexivo = ifelse(Pron_reflexivo == "No", "No RM", "RM")) %>%
mutate(Area_dialectal = ifelse(Area_dialectal == "Resto", "Rest of the territory", "Northwest")) %>%
count(Area_dialectal, Tipo_dativo, Pron_reflexivo) %>%
group_by(Area_dialectal, Tipo_dativo) %>%
mutate(total=sum(n), prop=(n/total*100))
##relevel factor
datives_types$Tipo_dativo <- factor(datives_types$Tipo_dativo, levels = c("Experiencer", "Cause", "Goal", "Possessive"))
#Dative types per area
##create table with RM probability by dative type and area
datives_types <- datives %>%
mutate(Pron_reflexivo = ifelse(Pron_reflexivo == "No", "No RM", "RM")) %>%
mutate(Area_dialectal = ifelse(Area_dialectal == "Resto", "Rest of the territory", "Northwest")) %>%
count(Area_dialectal, Tipo_dativo, Pron_reflexivo) %>%
group_by(Area_dialectal, Tipo_dativo) %>%
mutate(total=sum(n), prop=(n/total*100))
##relevel factor
datives_types$Tipo_dativo <- factor(datives_types$Tipo_dativo, levels = c("Experiencer", "Causer", "Goal", "Possessive"))
#generate plot
ggplot(datives_types, aes(x = Tipo_dativo, y= prop, group = Pron_reflexivo)) +
geom_col(aes(fill=Pron_reflexivo), position = "fill") +
labs(title="Frequency of the RM in anticausative verbs \nby dative type and geographical area", x="Dative type", y="Frequency of the RM", fill="Reflexive Marker") +
geom_text(aes(label = n), position = position_fill(vjust = .5)) +
theme_classic() +
scale_fill_manual(values=c('darkgrey','lightgray')) +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
facet_wrap(~ Area_dialectal)
##save plot
ggsave("antic_dative_types.png", height = 4, width = 6) #saves the last plot
